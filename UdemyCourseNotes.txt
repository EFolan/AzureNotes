User defined routes - IP forwarding

Scenario: Desire forcing net traffic to travel a particular route from azure to your system before having access to the internet.

Azure portal > New > Everything > Route Table

Created route table default has no routes.

Go into routes. Add route.

Route name: name; Address prefix: 0.0.0.0/0 = all traffic

Next Hop type: Virtual network gateway functions as a site to site vpn, forcing all traffic to go via that route.

Route table now contains one route but isn't associated with a subnet.

Go to subnets and search/add the relevant subnet to apply the route table rules.

---

Firewalls are provided in the Azure marketplace.

Being set up is the same as a Route table in that you'd need to force all subnet traffic through the firewall in order for it to be effective.

--------------

Availability sets

Multiple VMs can be placed in an availability set (as long as they are similar or serve similar purposes.)

MS will allocate these VMs across their own servers/networks in order to help guarantee a high percentage of availability. 

A new availablity set can be created while standing up new VMs

VMs created: 

Avail-Set-1
User: EFolan
Pass: Chr0ma

Avail-Set-2
Same User and Pass

----------------

Use External and Internal load balancing

Fault domains:
The hardware upon which the VMs run. Different fault domains ensure that not all your VMs share the same hardware.

Update domains:
Updates will never hit all your VMs at once. MS will update one update domain at a time.


Load balancers:

Search load balancers > MS has one > Create.

Public: Traffic that comes in from the internet. Load balancer will distribute this traffic between VMs

Internal: Same but Between internal infrastructure

Probes check if sites are still up

Backend Pools > Create

Machines in Availability set can be added to pool

Back end pool now has all x VMs from the availability set.


Health probes:

Load balancer needs a way to see if VMs are alive. So we use the health probe.

Can be customised to web ports etc.

Will check web page every x seconds and after 2 failed checks determines that this VM has failed.


Load balancing rules: What are we going to do when traffic comes in.

Can specify port mapping shich forces traffic off of port 80 (for example) to port 8000 on the backend machines.

Session persistence: (AKA sticky sessions) None: any user can go to any VM at any time.


-------

Use Application gateway

Relatively new alternative to load balancer.

Only does web based load balancing : http or https

Has a firewall option.

Cookie based session affinity

Secure Sockets Layer SSL installed on the application gateway rather than on the web server giving the server the chance to just do its web server work and not worry about SSL.

              Internet
                  |
                  V
Azure Traffic manager(DNS load blncr)
_________________|______________
|                              |
V                              V
Azure                        Azure   
Load                          Load
balancer                    balancer
   _|_                         |
   VVV                         V
3x Application Gateway      1 App GW
    XXX                       |||
  VVVVVVV                     VVV
VM|VM|VM                    VM|VM|VM


------------------------------------

Scaling VM sizes

Desire: Scale VM up from A0 to A1 etc.

Virtual machine > Settings > Size > Size choice.

Can take some time to migrate VM.

---------------------------------

Virtual machine scale sets
            
Search VM Scale set

Allows me to allocate several VMs under a single name.

Must be created in a new resource.

REquires a public IP Address
Allows us to assign a domain name upon creation.

Choose OS image same as usual.

Allowed to choose between 1 and 200 instances

Choose machine size...

Autoscale:

When enabled  we can choose a minimum and maximum number of VMs. Can also set a CPU threshold in % for the set to start scaling up the amount of VMs

Also allows Scale down threshold to be set in %

Also: Legal disclaimer saying that VM scale sets can and will deploy multiple azure resources as needed.

This allows all the work of creating multiple VMs to be done rather quickly.

-------------------------------

ARM VM Storage

After creating a VM with a size that allows two disks it is possible to spin up and associate another disk. under Settings > Disks

Plan for storage capacity:

The A series allows local physical HDD of 20GB only.

They allow an additional data disk (Blob storage) to be spun up alongside.

There are limitations on the throughput of that data disk in the A series.

An S as part of the VM series name that means it includes an SSD
EG: DS1, DS2 etc

------

Geo replication options

When creating storage accounts there is a replication option

Lowest level of replication is Locally redundant storage.

3 copies of your files stored locally within the one data centre, spread across multiple locations. 
If one hard disk fails then yours can be rebuilt and restored from copies.

Zone redundant storage stores files within the Geo but in different physical locations.

The Geo could be USA or China etc

Geo redundant storage:
Stores six copies of your files around the world.

REad access Geo redundant storage:
Sets up Read accessible copies around the world.

-----

Premium or standard storage

Differences are a req of the exam

Premium storage is stored on SSDs: No magnetic disks or heads with very low latency.

More expensive than standard storage and only certain types of VM support premium (THe ones with S in the type name)

Premium ONLY supports Locally Redundant Storage

In a HDD environment there is a max of 500 operations per second.

In Premium limits are the expected value rather than peaks.

It's good to really go over these differences for the exam.


---------------------------------


Monitor Azure Virtual machines

It's possible to create alerts for when the % CPU usage breaches a certain threshold.

It can notify us via email or webhook.

Diagnostics:

Allows different types of diagnostics for .net, SQL, ASP etc etc etc.

Can choose one or several different kinds of diagnostics which will be created in a chosen storage account. 

All this can be found in the Monitoring section under VMs.

Good practice to read more up on this as we go along.

--------------------------------

Overview of availability sets

Objective 1.7: MAnaging ARM availability.

Can be managed through availability sets.

Inside Availability set there are a number of VMs.

The AS is configured to have x amount of fault domains and x amount of update domains.

Fault domains:
The separate hardware locations your VMs are running on. An AS with two Fault domains will be able to split it's VMs between two separate pieces of hardware, meaning if one fails the other will still be up and running.

Update domains:
Microsoft will never push updates to all update domains at a time. They will go one after the other meaning that if VMs are spread over Update domains they won't all be incapacitated by updates simultaneously.

Domains are zero indexed in the list in Azure portal.

MS has a service agreement of 99.95% uptime if you have two or more VMs running in an availability set.

----------------------------------------
End of Objective 1
----------------------------------------
----------------------------------------

Objective 2: Design and implement a storage and data strategy... 25 - 30% of final score.
----------------------------------------

Create a storage account

Generally you'll use standard (General storage) storage and use Blob storage when you need storage specifically calibrated for blobs.

There's an option for performance: Standard and Premium. We've covered this already. Standard is on HDDs and Premium is on SSDs.

There'll be an option to set the desired replication level. Again, we've covered this before. Typically we'll pick LRS; locally redundant storage. The other options are covered in detail further up.

Let's go over them anyway.

LRS:  Stores three copies of your data in separate physical locations but in the same data centre.

Zone redundant Storage:
Stores three separate copies of your data across different location 'zones' but within the same Geo location. So Data may be spread across the US or China.

Geo redundant Storage:
Six copies of the data are stored across the globe.

Read Accessible Geo redundant storage:
Same as above except you have read access to your file copies.


Encryption is also available.

If we need the data encrypted on the disk it is possible here.

Resource group and location are created as usual.

----------------------

Put a cdn in front of a storage account

CDN: Content Delivery network

Demonstrate adding a CDN to a storage account.

Create a public container with Blob access type which can be public.

Upload a file.

Search CDN: MS provide a CDN for various large file types that can be placed in various geographical locations around the world.

Create and place in the appropriate resource group.

Pricing tiers are varied and provided by various sources such as Verizon, Akamai etc.

After creation:

We have 0 endpoints so we're going to want to set one up.

An endpoint is the new url for your content.

Choose a unique name for the endpoint. 

Origin type: Storage

Origin path the path that directs to the CDN:

/publicfiles in the video.
This is the path to our public container

Leave origin host header.

It'll create an endpoint.

CDN gets pointed to container so container name not required.

----------

Add directories and subdirectories to Blob containers

Can be coded to create a directory structure as needed.

------------------

Use Custom domain names with storage accounts

Can we customise the domain name of a blob/container without a CDN? Yes.

Custom domain property of the Storage account.

Create a CNAME record with a DNS provider that points from your domain to the blob.core.windows.net address.

THis method is simple but requires brief downtime while Azure verifies the domain registration.

Alternately:

Create a CNAME record with your DNS provider that [pints from the asverify subdomain EG asverify.mydomain.com to the asverify subdom of the container url. After this completes you can create a CNAME tat points to the container url standard. 

This method won't incur any down time.

When using this method check the "use indirect CNAME validation" checkbox.

-----------------

Scale a blob container

There are limits of storage accounts in Azure

Max TB in a single storage account: 500 terabytes

One container/blob, table or queue can contain the 500TB. They have a max size of 500TB.

Max size of block blob is approx 195GB. Actual: 50,000 X 4MB

Max size of a page blob is 1TB

Also a limit on operations per second.
MS measures these in 8KB chunks called  8KB IOPS. 
The limit is 1000 8KB IOPS per share.

Sharding: With a storage account and a container, if you need to create 500 1TB files the only option is to create another storage account.

This will double your limits.

A problem to consider is how to divide the data between multiple storage accounts. Options exist such as indexing based on file alphabetical order or round robin etc.

--------------------------------------

Objective 2.2: Implement table and queue storage.

Table storage is a noSQL table structure.

You can create your own data structures and it is extremely fast.

Good option for fast flexible data.

----
Insert data into a table

Creating and adding to table storage in the code examples.

Partition Key: a key that defines the kind of entity that is being held in storage. 
For instance if a CarEntity is stored then the partition key should be "car". Similarly, a TruckEntity would have partition key: "truck".

RowKey: This is the primary key for the item in question. Should be unique in its table.

-----
Retrieve an Object from a Table

-----

Transactions

In SQL Server you can wrap a set of operations in a transaction and if one of them fails none of them will complete.

Within table storage Transactions are handled with TableBatchOperations.

Executed in a Batch: Either they all work or they all fail.

Some rules, drawbacks:

In order to work, every operation in a batch must be performed on objects with the same Partition key.

Limit of 100 operations that can be in a batch together.

Only one operation per row.

Create a TableBAtchoperation instance.
Insert all new objects into the batch.
Execute the batch operation.

------

Create your first Queue...
Queue creation in code snippet for table storage

Azure Storage naming conventions:

Storage account:
Length: 3 - 24
lowercase only
valid chars: alphanumeric

Blob names:
length: 1 - 1024
case-sensitive
valid chars: any url chars

Container name
length: 3 - 63
lowercase only
valid chars: alphanumeric and dash

Queue name
length: 3 - 63
lowercase only
valid chars: alphanumeric and dash

Table name:
length: 3-63
case-insensitive
valid chars: alphanumeric

---------

Shared access signatures

Accessing Blobs via URL can result in access issues if users don't have access.

The access keys under the menu are owner access keys. These give full access and should not be handed out.

Shared access signature under Settings.

Allows granting access to any og the types in the storage account.

The shared access signature token functions as a URL query string with the following parameters:

sv: Not sure, 2016-05-31

ss :Allowed services(b: blob,   f: file, q: queue, t: table)

srt: Resource Types(s: service, c: container, o:    object)

sp: Permissions (Read, Write, Delete, List, Add, Create, Update, Process)

se: End time(yyyy-MM-ddTHH:MM:SSZ)

st: Start time (Same format)

spr: allowed protocols(https only or http and https)

sig: signature key

---

Stored Access Policy

Create a shared access policy via code and store the access policy against a policy name which can be changed after the fact. 

If you need to change the policy after creating it, always use a stored access policy. It'll be possible to change it without having to generate a new URL.

---

Regenerate access keys

Easy to regenerate and can be done under access keys in portal.

After regenerating, all keys in code must be changed to reflect regenerated key.

----------

Configure CORS Cross Origin Access

CORS: Cross Origin Resource Sharing

CORS allows a secure way to allow one domain to call APIs in another domain.

If elements like iframes or scripts that will be embedded into an app or project will be hosted on storage then CORS is an ideal way for the app to reference them.

Can add CORS rules by navigating to CORS under storage and adding a rule.

Can also be done programmatically via the ServiceProperties of the Blob Client and using CorsRules.Add()

---

View Diagnostics for Storage

Activity logs in the storage account allow queries to generate reports about which resources are being accessed, how many etc etc.

There's also dianostics under Monitoring. 

Diagnostics can be turned off or on and are displayed on the general page for a storage account.

Retention can be altered to store diagnostics for longer or shorter period.

-----------------------------
Objective 2.4: Implement Azure SQL Databases

Azure SQL Database  is a clud database service. Allows scaling without downtime and built in advisors to help maximise performance.

Pricing:

Elastic database model

A pool of resources: can setup a large number of databases that pull resources from a single pool.

Single database model

Managed at the database level.
More usual pricing tiers that specify memory, storage, power available.

MS measures DB performance in DTUs

DTU: Database transaction units

A DTU is essentially every measure(memory, comp power, storage etc) given a score of up to five and measured together. 

When creating a SQL database: Collation refers to the character set used. We can leave this as the default.

---

Configure Geo-Replication for SQL Databases

Geo-Replication under settings.

Geo-Replication allows you to create a backup copy of your DB in whichever region you choose. MS takes care of the replication process.

Reasons:
Emergencies: the region goes down or the db goes down.

Useful for reporting. 
Long running reports don't have to be run against the primary active DB but can be against the backup DB.

This involves creating another DB so going through the steps of creating a new server. 

Secondary type: Readable.

No Elastic Pool for our demo.

This creates a geo replicated secondary database for the selected region.

Any changes from the first will be auto replicated to the second DB.

---

Set a firewall rule to allow access to SQL

We want to be able to interact with this DB.

bcp command

Bulk copy command

Can be used to import data to a sql server

This can also be done via the visual studio tool.

Before doing this we need to open a hole in the firewall to allow access to the SQL server DB.

TO do this we need our current IP address.

In the portal use Set Server Firewall tab in sql server settings and add our IP address to the allowed list. Granting us access to the server.

--- 
Creating a connection

Within visual studio, open the server explorer and right click -> add connection. Choose Sql Server connection and fill out the server name from Azure along with the sql connection credentials we added when creating the DB.

This can allow you to connect to a DB on the SQL Server.

---

Restore Data using Point-In-Time Restore

Restore option within DB overview.

Gives the ability to restore a DB to a specific point in time.

You can specify a restore point by a certain time.

It will create a new DB using the snapshot from the specified time.

Basic tier DB only allows 7 days of Point-In-Time restore.

Standard tier(S0, S2 etc) Gives 30 days restore time.

Premium tier allows over a month

No cost for having the backup capability but there is a cost associated with running a restore.

--------------

Objective 2.5: Implement Azure DocumentDB (Now CosmosDB)

CosmosDB actually works using JSON rather than fully unstructured like Blobs, Table storage etc.

CosmosDB also provides more complex querying than table storage

---

Create a collection and DocumentDB Database

Add collection from the top menu

Collection gets a unique id and a pricing tier.

Can create new database and give it a name.

RU request units per second

---

Upload documents to CosmosDB

Documents are JSON Files

Settings > Documen explorer
Can upload up to 100 JSON docs at a time.

Example document:

{
  "id": "2",
  "colourName": "Green",
  "value": "#0f0"
}

---

Query CosmosDB

Query explorer from within Azure portal

Starting query is SELECT * FROM c

Can query CosmosDB like SQL

SELECT * FROM c WHERE c.colourName = "Red" 
is valid

-----------

Objective 2.6: Implement Redis Caching

redis.io is the homepage

Redis is an open source, in-memory data store.

Very popular, available for almost every potential server, language, technology available.

Because it runs in memory it is one of the fastest ways of storing and retrieving data available.

In Azure storage or SQL Databases things are stored in disc storage but redis stores everything in memory.

This gets extremely volatile should a server go down etc. Everything in memory is forfeit.

Redis is for data that you don't mind losing. Perfect for caching.

Web caching server stores some information from DB so it doesn't have to keep going back to the db to retrieve it.

Creating:

New > Redis Cache for MS

Comes in Basic,  Standard and Premium.

Name it and set resource group.

Pricing tiers:

Basic tier: Cheapest, low amount of memory for storage (250MB)

Standard: Higher memory (1GB) with replication and 99.9% Similarly

Premium: Data persistence: Allows storing a backup of your redis cache to a disk in a storage account.
Also, networking and clusters.

---

Implement Redis Caching

Redis server activated and running:

persistence

Redis Data Persistence tab in Settings

Enable RDB Backup and set a backup frequency (60 minutes here).

It does need a storage account to run backups.

Redis cache is ready to go.

---

Implement Security and Configure networking

By default Redis cache is not running on a network but can be accessed using a key/access permissions.

A premium Redis cache can be created on a virtual network, the cache is then assigned to a specific subnet.

When the cache is added to a virtual network I can put the network security group settings on the virtual network and do all the filtering and routing via the virtual network, ensuring that the cache is inaccessible to the wider internet.

The cache must have its own subnet.

Subnets can talk within a virtual network.

Cannot add a network to a redis cache so make sure and add the network during redis creation.

---

Use Redis Cache in a clustered setting

Cluster: a number of servers that operate as a single unit.

Under a premium tier this is available.

When clustering is enabled azure will distribute the cache over the amount of servers that you specify. In this case: 4 with a total size of 24GB.

This does incur a cost.

As a developer you're just accessing redis without worrying about how it is deployed.

It is possible to just access one of the servers if need be: If one of the servers goes down etc.

---

Activity: Create a Redis Cache

Key point: understand the differnet tiers, what they offer and how choosing a tier may be affected by various restraints in a company/environment.

--------------------

Objective 2.7: Implement Azure Search

Azure offers a search as a service solution where azure will index your data and a developer can query the search engine to provide results to the users.

Standard creation with name, resource group and pricing tier.

free tier is limited to 50MB with shared resources and 3 indexes.

Basic tier offers 5 indexes with 2 GB of storage, dedicated resources and scaling of up to 3 search units.

Standard adds the concept of partitions:
One part of your data can be indexed by one server and another by a different server. Splits up the workload.

Each Partition can have replicas so there can be up to 2 replicas for each partition, further splitting the workload.

Any combinitation of partitions and replicas multiplyed together must not exceed the number of search units available at the tier.

Choose Free tier for now.

---

Create a Search Index

Search service is created but we don't have any indexes.

Settings > Add Index

Add fields to correspond with a primary key.

id : primary key
name
description
thumbnail
baserate
baseraterange : cheap|moderate|high : Facetable
freeparking: boolean


Various properties are available for each field:

Retrievable:
Whether this field can be retrieved and displayed in a search result

Filterable:
Allows filter to be used in queries EG WHERE name = ...

Sortable: Whether results can be sorted by the field

Facetable:
Facets are a different type of navigation in a search. Facets can be seen as categories of results. If all results are either 1 or 2 then this has two facets.

Searchable:
THe field is used to match the search results.

---

Import data for indexing

Indexes can be created via a data source.

Click import data and we're given a set of data stores from which to choose.

We can also use some test sets of data which we do in the lesson.

The next step is to create an indexer.

An indexer is a job that'll either run one time or on a schedule. It will take the data from the data source and refresh the search and indexes based on any changes.

Inside the index the search explorer allows querying of the data.

----------------------
----------------------

Objective 3: Manage Identity, application and network services

In this case, less about true networking and the associated security aspects but about authentication, messaging and networking within the realms of application development.

----------------

Objective 3.1 Integrate an app with Azure Active Directory (AAD)

AD is one of the most common identity management solutions for companies around the world.

Azure Active Directory is a separate product to AD and extends the services of the latter into the cloud.

AAD is not a replacement for on premises AD. It is a smaller subset of the features of AD. Intended to provide ID and authentication services to mobile and web based applications on the public network that is connected to the on premises AD allowing single sign on between premises and internet hosted applications.

Identity as a service IDaaS

Microsoft now has a preview mode of the Azure Active Directory new portal.

AAD is easy to create in the portal.

---

Implement WS-Federation with AAD

Federation is the concept that AAD does not contain the user's password. Federation works as follows:

You pass the user id and you pass a token. A third party does the authentication with the password and passes a token which is passed to AD. AD verifies the token and allows access.

Federation is supported for AAD.

For the exam we'll need to know WS-Federation, SAML and OAUTH types of Federation.

Instead of developing code from scratch MS provide various samples for the different Federation types.

Link for WS-Federation:
https://github.com/Azure-Samples/active-directory-dotnet-webapp-wsfederation



















